{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCarsDd3EZu9tlcOFi2K9G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImSittingOnSalt/Pizza-or-not-/blob/main/ItWorks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "8Q-lIXAIVoWz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader , random_split\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as model\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import pathlib\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "folder_path = '/content/drive/My Drive/pizza_not_pizza/pizza/'\n",
        "images = []\n",
        "\n",
        "for file_name in os.listdir(folder_path):\n",
        "    if file_name.endswith(\".jpg\") or file_name.endswith(\".png\"):\n",
        "        img = Image.open(os.path.join(folder_path, file_name))\n",
        "        images.append(img)\n",
        "\n",
        "print( images[0], images[235], images[747], images[43])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC__IDY3ThV0",
        "outputId": "30e19899-5ca6-4c08-f24a-8177f4507d8e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x385 at 0x7CD2A5AEAB00> <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x341 at 0x7CD2A587D810> <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x382 at 0x7CD2A56B6920> <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512 at 0x7CD2A59C49A0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаю имена классов\n",
        "data_dir = pathlib.Path('/content/drive/My Drive/pizza_not_pizza/')\n",
        "class_names = [item.name for item in data_dir.glob('*')][:2]\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mggAF8tEeihO",
        "outputId": "a58b698a-44ff-4b5c-94df-063e3ed27fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pizza', 'not_pizza']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pizza_dir = '/content/drive/My Drive/pizza_not_pizza/pizza/'         #дирректории классов\n",
        "not_pizza_dir = '/content/drive/My Drive/pizza_not_pizza/not_pizza/'"
      ],
      "metadata": {
        "id": "j3zr8LN5fHY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_pizza_img = len(os.listdir(pizza_dir))          #сколько фотов пицы......\n",
        "len_not_pizza_img = len(os.listdir(not_pizza_dir))\n",
        "print(len_pizza_img, len_not_pizza_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKyzImJ9ffZ5",
        "outputId": "95e96e8d-855e-4dc1-b80d-1063b693ab10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "983 983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualizing images**"
      ],
      "metadata": {
        "id": "vcfR8KBsgwDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(images[301])\n",
        "# plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-Vp-2wuFcX1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "# Разделение на тренировочный и валидационный наборы\n",
        "train_size = int(0.7 * len(dataset))  # 70% для тренировки\n",
        "val_size = len(dataset) - train_size\n",
        "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Define data loaders with batch size\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "_jcKcK5BhKpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Рисую рандомные картинки\n",
        "def plot_random_images():\n",
        "    images, labels = next(iter(train_loader))  # Беру батч изображений с классами\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    for i, (image, label) in enumerate(zip(images, labels)):\n",
        "        plt.subplot(4, 5, i + 1)\n",
        "        plt.imshow(image.permute(1, 2, 0))  # Переключить отображение в порядке RGB\n",
        "        plt.title(class_names[label])\n",
        "        plt.axis('off')\n",
        "        if i == 20:\n",
        "            break\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ARcQBdhVuF-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_random_images() #выдаёт ошибку, не понимаю в чём мем, но картинки всё равно рисует :)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hDABcWycxpLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedModel, self).__init__()\n",
        "\n",
        "        # Определение сверточных слоев здесь\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 24, kernel_size=3, stride=1, padding=1), # 2D сверточный слой с: Входными каналами,Выходными каналами, Размером ядра: 3x3, Шагом: 1, Отступом: 1\n",
        "            nn.BatchNorm2d(24),                                   # Нормализация по батчам.\n",
        "            nn.ReLU(),                                            # Функция активации\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),                # Макс. пулинг для понижения дискретизации и уменьшения пространственной размерности.\n",
        "\n",
        "            nn.Conv2d(24, 40, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(40, 80, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(80),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(80, 160, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(160),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(160, 160, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(160),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(160, 320, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(320),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(320, 320, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(320),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)) #Адаптивный пулинг по среднему значению, автоматически подстраивающийся под размер входных данных\n",
        "        )\n",
        "\n",
        "        # Определение полностью связанных слоев здесь\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),         # Преобразует выход из сверточных слоев в 1D вектор\n",
        "            nn.Linear(320, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 42),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(42, 1),     # Выходной слой с 1 единицей (бинарная классификация)\n",
        "            nn.Sigmoid()          # Для получения вероятности принадлежности к одному из классов (0 или 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Dqox80oEA1aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(train_loader, val_loader, epo, mdl=None): # rate was taken empirically. This value is optimal in the base\n",
        "    print(f\"Train size:\\t\\t{len(train_loader.dataset)}\\n\"\n",
        "          f\"Validation size:\\t{len(val_loader.dataset)}\\n\")\n",
        "\n",
        "\n",
        "    model = mdl if mdl is not None else ImprovedModel()\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "    history = []\n",
        "    for epoch in range(epo):\n",
        "      model.train()  # Установить режим обучения для модели\n",
        "      train_loss = 0.0\n",
        "      for data, target in train_loader:\n",
        "        target = target.unsqueeze(1)  # Добавить измерение для соответствия выходному размеру\n",
        "        target = target.clone().detach().float()\n",
        "        # Прямой проход (forward pass)\n",
        "        output = model(data)\n",
        "\n",
        "        # Вычислить ошибку (loss)\n",
        "        loss = loss_fn(output, target)\n",
        "        # Обратный проход (backward pass) и обновление весов\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "      model.eval()  # Установить режим оценки для модели\n",
        "      with torch.no_grad():  # Отключить вычисление градиентов для валидации\n",
        "        val_loss = 0.0\n",
        "        val_acc = 0.0\n",
        "        for data, target in val_loader:\n",
        "          output = model(data)\n",
        "          val_loss += loss_fn(output, target).item()\n",
        "          val_acc += (output.round() == target).sum().item()\n",
        "        val_acc /= len(val_loader.dataset)\n",
        "\n",
        "      # Сохранить информацию об эпохе в history\n",
        "      history.append((train_loss / len(train_loader), val_loss / len(val_loader), val_acc))\n",
        "\n",
        "      print(f\"Epoch: {epoch+1}/{epo}\\tTrain Loss: {train_loss:.3f}\\tVal Loss: {val_loss:.3f}\\tVal Acc: {val_acc:.3f}\")\n",
        "\n",
        "    return val_acc, history\n",
        "\n",
        "def outputs(model_type, text, plot):\n",
        "    print(f\"{model_type} Accuracy: {text:.3f}\\n\")\n",
        "    plt.plot_history(plot, \"loss\")"
      ],
      "metadata": {
        "id": "a4_dBdS_OjjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, history = train_and_evaluate_model(train_loader, val_loader, epo=25)  # сейчас споткнулась тут, не получается, думаю"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "NIoiik9cOkdA",
        "outputId": "48b22db4-d16a-4aec-81bf-d0206a4f3f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size:\t\t1376\n",
            "Validation size:\t590\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "expected scalar type Long but found Float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3ae9bc517424>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# сейчас споткнулась тут, не получается, думаю\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-55a3f6509a20>\u001b[0m in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(train_loader, val_loader, epo, mdl)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Вычислить ошибку (loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Обратный проход (backward pass) и обновление весов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1186\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
          ]
        }
      ]
    }
  ]
}